apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: detect-trees-workflow-
spec:
  serviceAccountName: argo
  entrypoint: main

  # Set imagePullPolicy for all containers in the workflow
  podSpecPatch: |
    containers:
      - name: main
        imagePullPolicy: Always

  # Affinity rules for workflow pods:
  # 1. nodeAffinity: Schedule on non-GPU nodes by default (GPU tasks override with affinity: {})
  # 2. podAffinity: Prefer nodes with other running workflow pods to minimize autoscaler evictions
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
              - key: nvidia.com/gpu.present
                operator: DoesNotExist
    podAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: workflows.argoproj.io/completed
                  operator: In
                  values:
                    - "false"
            topologyKey: kubernetes.io/hostname

  # A list of input parameters available to the workflow at runtime.
  # These parameters can be referenced throughout the workflow templates using {{workflow.parameters.<name>}}
  arguments:
    parameters:
      - name: CAMERAS_FILE
      - name: MESH_FILE
      - name: DTM_FILE
      - name: IMAGE_FOLDER
      - name: ORIGINAL_IMAGE_FOLDER
      - name: CHM_FILE
      - name: OUTPUT_FOLDER
      - name: SPECIES_MODEL_PATH
      - name: SPECIES_CONFIG_PATH
      - name: LD_MODEL_PATH
      - name: LD_CONFIG_PATH
      - name: MESH_CRS
        value: 26910
      - name: CHIP_SIZE
        value: 4000
      - name: CHIP_STRIDE
        value: 3600
      - name: N_WORKERS
        value: 4

  # Defining where to read raw drone imagery data and write out imagery products to `/ofo-share`
  volumes:
    - name: data
      persistentVolumeClaim:
        claimName: ceph-share-rw-pvc2

  templates:
    # the 'main' template defines the order of high-level steps to be completed in the workflow.
    # the 'process-datasets' step has a looping directive (withParam) which goes through each dataset name and processes it.
    - name: main
      steps:
        - - name: detect-trees
            template: detect-trees
            arguments:
              parameters:
                 - name: chm-file
                   value: "{{workflow.parameters.CHM_FILE}}"
                 - name: detected-trees-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/detected_trees.gpkg"
        - - name: render-instance-labels
            template: render-instance-labels
            arguments:
              parameters:
                 - name: mesh-file
                   value: "{{workflow.parameters.MESH_FILE}}"
                 - name: cameras-file
                   value: "{{workflow.parameters.CAMERAS_FILE}}"
                 - name: dtm-file
                   value: "{{workflow.parameters.DTM_FILE}}"
                 - name: trees-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/detected_trees.gpkg"
                 - name: mesh-crs
                   value: "{{workflow.parameters.MESH_CRS}}"
                 - name: image-folder
                   value: "{{workflow.parameters.IMAGE_FOLDER}}"
                 - name: original-image-folder
                   value: "{{workflow.parameters.ORIGINAL_IMAGE_FOLDER}}"
                 - name: render-savefolder
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/renders"
        - - name: chip-images
            template: chip-images
            arguments:
              parameters:
                 - name: images-folder
                   value: "{{workflow.parameters.IMAGE_FOLDER}}"
                 - name: renders-folder
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/renders"
                 - name: output-folder
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/chips"
        - - name: classify-chips-species
            template: classify-chips
            arguments:
              parameters:
                 - name: chips-folder
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/chips"
                 - name: model-path
                   value: "{{workflow.parameters.SPECIES_MODEL_PATH}}"
                 - name: config-path
                   value: "{{workflow.parameters.SPECIES_CONFIG_PATH}}"
                 - name: output-path
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/classified-chips-species.json"
        - - name: classify-chips-live-dead
            template: classify-chips
            arguments:
              parameters:
                 - name: chips-folder
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/chips"
                 - name: model-path
                   value: "{{workflow.parameters.LD_MODEL_PATH}}"
                 - name: config-path
                   value: "{{workflow.parameters.LD_CONFIG_PATH}}"
                 - name: output-path
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/classified-chips-LD.json"
        - - name: assign-species-predictions-to-trees
            template: assign-predictions-to-trees
            arguments:
              parameters:
                 - name: input-trees-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/detected_trees.gpkg"
                 - name: image-level-predictions-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/classified-chips-species.json"
                 - name: column-name
                   value: "species_prediction"
                 - name: output-trees-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/detected_trees_w_species.gpkg"
        - - name: assign-live-dead-predictions-to-trees
            template: assign-predictions-to-trees
            arguments:
              parameters:
                 - name: input-trees-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/detected_trees_w_species.gpkg"
                 - name: image-level-predictions-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/classified-chips-LD.json"
                 - name: column-name
                   value: "live_dead_prediction"
                 - name: output-trees-file
                   value: "{{workflow.parameters.OUTPUT_FOLDER}}/detected_trees_w_species_and_live_dead.gpkg"
## Definitions of individual steps (templates)
    - name: detect-trees
      inputs:
        parameters:
          - name: chm-file
          - name: detected-trees-file
      container:
        image: ghcr.io/open-forest-observatory/tree-detection-framework:feature-dr-containerize
        volumeMounts:
          - name: data
            mountPath: /data
        command: [
                  "python",
                  "-m",
                  "tree_detection_framework.entrypoints.generate_predictions",
                  "--raster-folder-path",
                  "{{inputs.parameters.chm-file}}",
                  "--tree-detection-model",
                  "geometric",
                  "--predictions-save-path",
                  "{{inputs.parameters.detected-trees-file}}",
                  "--chip-size",
                  "{{workflow.parameters.CHIP_SIZE}}",
                  "--chip-stride",
                  "{{workflow.parameters.CHIP_STRIDE}}"
                ]
    - name: render-instance-labels
      inputs:
        parameters:
          - name: mesh-file
          - name: cameras-file
          - name: dtm-file
          - name: trees-file
          - name: mesh-crs
          - name: image-folder
          - name: original-image-folder
          - name: render-savefolder
      container:
        image: ghcr.io/open-forest-observatory/geograypher:main
        volumeMounts:
          - name: data
            mountPath: /data
        command: ["python",
            "-m", "geograypher.entrypoints.render_labels",
            "--mesh-file", "{{inputs.parameters.mesh-file}}",
            "--mesh-CRS", "{{inputs.parameters.mesh-crs}}",
            "--cameras-file", "{{inputs.parameters.cameras-file}}",
            "--texture", "{{inputs.parameters.trees-file}}",
            "--DTM-file", "{{inputs.parameters.dtm-file}}",
            "--image-folder", "{{inputs.parameters.image-folder}}",
            "--render-savefolder", "{{inputs.parameters.render-savefolder}}",
            "--texture-column-name", "unique_ID",
            "--ground-height-threshold", "2.0",
            "--original-image-folder", "{{inputs.parameters.original-image-folder}}"]
    - name: chip-images
      inputs:
        parameters:
          - name: images-folder
          - name: renders-folder
          - name: output-folder
      container:
        image: ghcr.io/open-forest-observatory/cv-utils:feature-dr-species-inference-pipeline
        volumeMounts:
          - name: data
            mountPath: /data
        resources:
          requests:
            cpu: 1
            memory: "2Gi"
          limits:
            memory: "4Gi"
        command: ["python", "/app/chip_images.py",
                  "{{inputs.parameters.images-folder}}",
                  "{{inputs.parameters.renders-folder}}",
                  "{{inputs.parameters.output-folder}}",
                  "--n-workers", "{{workflow.parameters.N_WORKERS}}"
                  ]

    - name: classify-chips
      inputs:
        parameters:
          - name: chips-folder
          - name: model-path
          - name: config-path
          - name: output-path
      # Disable workflow-level non-GPU affinity; let GPU resource request handle node selection
      affinity: {}
      script:
        image: waikatodatamining/mmpretrain:1.2.0_cuda11.1
        volumeMounts:
          - name: data
            mountPath: /data
        resources:
          requests:
            nvidia.com/mig-1g.5gb: 1
          limits:
            nvidia.com/mig-1g.5gb: 1
        command: ["python"]
        source: |
          import json
          from pathlib import Path

          from mmpretrain.apis import ImageClassificationInferencer

          input_folder = Path("{{inputs.parameters.chips-folder}}")
          config_path = "{{inputs.parameters.config-path}}"
          model_path = "{{inputs.parameters.model-path}}"
          output_path = Path("{{inputs.parameters.output-path}}")

          # Listing input files
          input_files = [
              str(f)
              for f in Path(input_folder).rglob("*")
              if f.suffix.lower() in [".jpg", ".jpeg", ".png"]
          ]
          print(f"Running on {len(input_files)} files")

          # Setting up the model
          inferencer = ImageClassificationInferencer(model=config_path, pretrained=model_path, device="cuda")

          # Run inference. This is the slow step.
          results = inferencer(input_files, batch_size=4)

          # Extract predicted classes
          pred_labels = [r["pred_class"] for r in results]

          # Build a dict from filename to predicted class
          results_per_file = {str(k): v for k, v in zip(input_files, pred_labels)}

          # Write out results
          output_path.parent.mkdir(exist_ok=True, parents=True)
          with open(output_path, "w") as file_h:
              json.dump(results_per_file, file_h)

    - name: assign-predictions-to-trees
      inputs:
        parameters:
          - name: input-trees-file
          - name: image-level-predictions-file
          - name: column-name
          - name: output-trees-file
      script:
        image: uhoosborne/geopandas:latest
        volumeMounts:
          - name: data
            mountPath: /data
        resources:
          requests:
            cpu: 1
            memory: "2Gi"
          limits:
            memory: "4Gi"
        command: ["python"]
        source: |
          import json
          import geopandas as gpd
          import pandas as pd
          import numpy as np
          from pathlib import Path

          column_name = "{{inputs.parameters.column-name}}"
          image_level_predictions_file = "{{inputs.parameters.image-level-predictions-file}}"
          input_trees_path = Path("{{inputs.parameters.input-trees-file}}")
          output_trees_path = Path("{{inputs.parameters.output-trees-file}}")

          with open(image_level_predictions_file, "r") as f:
              preds = json.load(f)

          input_files = list(preds.keys())
          labels = list(preds.values())

          tree_IDs = [Path(f).stem for f in input_files]

          preds_df = pd.DataFrame({"tree_ID": tree_IDs, column_name: labels})


          def fair_mode(series):
              """Tie break if there two or more options"""
              modes = series.mode()
              mode = np.random.choice(modes)
              return mode


          grouped = preds_df.groupby(["tree_ID"]).apply(lambda x: fair_mode(x[column_name]))
          grouped = pd.DataFrame({"unique_ID": grouped.index, column_name: grouped.values})
          grouped["unique_ID"] = grouped["unique_ID"].astype(str)
          grouped["unique_ID"] = grouped["unique_ID"].str.pad(5, fillchar="0")
          grouped["unique_ID"] = grouped["unique_ID"].astype(str)

          detected_trees = gpd.read_file(input_trees_path)
          detected_trees["unique_ID"] = detected_trees["unique_ID"].astype(str)
          detected_trees = detected_trees.merge(grouped, on="unique_ID", how="left")

          # create output folder
          output_trees_path.parent.mkdir(parents=True, exist_ok=True)

          detected_trees.to_file(output_trees_path)